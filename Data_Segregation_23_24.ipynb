{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNctS5TQIP92wUplfntMgAN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Magaton1010/Python_Analysis/blob/main/Data_Segregation_23_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Segregation Tutorial\n",
        "\n",
        "This repository contains a Python script that demonstrates the process of segregating data from multiple Excel files based on specific criteria. The script uses the pandas library for data manipulation and follows best practices for code readability and efficiency.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The provided Python script reads Excel files from a specified input folder, performs data segregation based on a sample ID column, and creates new columns with transformed data. The script deletes unnecessary columns, creates new columns based on farm ID, and applies various transformations.\n",
        "\n",
        "## Features\n",
        "\n",
        "- Input folder and output folder paths are easily customizable.\n",
        "- The script processes each Excel file in the input folder.\n",
        "- Unnecessary columns are deleted to streamline the data.\n",
        "- New columns are created based on the farm ID, including crop type, site, season, and more.\n",
        "- The script handles different farm IDs with specific depth and treatment keys.\n",
        "- The \"Sampling Date\" column is converted to a datetime object with a specific format.\n",
        "- The final data is saved to new Excel files in the output folder.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. Clone the repository to your local machine.\n",
        "2. Install the required dependencies: `pip install pandas`.\n",
        "3. Customize the input and output folder paths in the script.\n",
        "4. Run the script to process your data.\n",
        "\n",
        "## Usage Example\n",
        "\n",
        "```python\n",
        "# Example command to run the script\n",
        "python data_segregation_script.py"
      ],
      "metadata": {
        "id": "DQ91dvnXR1VH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmnVAP70Rp9M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Set the folder paths for input and output files\n",
        "input_folder = r''\n",
        "output_folder = r''\n",
        "\n",
        "# Get a list of all Excel files in the input folder\n",
        "excel_files = glob.glob(os.path.join(input_folder, '*.xlsx'))\n",
        "\n",
        "# Process each Excel file\n",
        "for file in excel_files:\n",
        "    # Read the Excel file\n",
        "    data = pd.read_excel(file)\n",
        "\n",
        "    # Ask for the columns to delete\n",
        "    columns_to_delete = ['AcctNo', 'Company', 'FieldID', 'First', 'Last', 'Address', 'City', 'State', 'Zip', 'Country', 'Grower', 'FarmID', 'LabID', 'Received', 'Processed', 'Matrix']\n",
        "\n",
        "    # Delete the specified columns\n",
        "    data.drop(columns=columns_to_delete, inplace=True)\n",
        "\n",
        "    # Ask for the sampleid column\n",
        "    sampleid_column = 'SampleID'\n",
        "\n",
        "    # Extract the data based on the fieldid column\n",
        "    if sampleid_column in data.columns:\n",
        "        # Get the first three characters of the fieldid column as the farm ID\n",
        "        farm_id = data[sampleid_column].apply(lambda x: x.split('-')[0])\n",
        "\n",
        "        # Create new columns based on the farm ID and perform the required transformations\n",
        "        block_key = {'A': '1', 'B': '2', 'C': '3', 'D': '4'}\n",
        "        crop_key = {'T1': 'TO', 'T2': 'TO', 'T3': 'TO', 'P1': 'PT', 'P2': 'PT', 'B1': 'GB', 'B2': 'GB'}\n",
        "        site_key = {'T1': 'LL', 'T2': 'PI', 'T3': 'LE', 'P1': 'TI', 'P2': 'TL', 'B1': 'CC', 'B2': 'HW'}\n",
        "        season_key = {'T1': 'F3', 'T2': 'W3', 'T3': 'W3', 'P1': 'W3', 'P2': 'W3', 'B1': 'W3', 'B2': 'W3'}\n",
        "        spatial_key = {'DR': 'DR', 'FN': 'FN', 'SN': 'SN', 'ND': 'ND'}\n",
        "\n",
        "        farm_ids = set(farm_id.tolist())\n",
        "        if 'T1' in farm_ids or 'T2' in farm_ids or 'T3' in farm_ids:\n",
        "            depth_key = {'S1': '15', 'S2': '30', 'S3': '45'}\n",
        "            treatment_key = {'1': '0', '2': '50', '3': '75', '4': '100', '5': '150', '6': '200'}\n",
        "        elif 'P1' in farm_ids or 'P2' in farm_ids:\n",
        "            depth_key = {'S1': '20', 'S2': '40', 'S3': '60'}\n",
        "            treatment_key = {'1': '0', '2': '46', '3': '92', '4': '137', '5': '183', '6': '229'}\n",
        "        else:\n",
        "            depth_key = {'S1': '5', 'S2': '30', 'S3': '45'}\n",
        "            treatment_key = {'1': '0', '2': '40', '3': '80', '4': '120', '5': '113L'}\n",
        "\n",
        "        # Create new columns based on the farm ID and perform the required transformations\n",
        "        data[\"Crop\"] = farm_id.map(crop_key)\n",
        "        data[\"site\"] = farm_id.map(site_key)\n",
        "        data[\"season\"] = farm_id.map(season_key)\n",
        "\n",
        "        # Convert \"Sampling Date\" to a datetime object and format it as MM/DD/YYYY\n",
        "        data[\"Sampling Date\"] = pd.to_datetime(data[sampleid_column].apply(lambda x: x.split('-')[5]), format='%m%d%Y').dt.date\n",
        "\n",
        "        data[\"sample_type\"] = \"S\"\n",
        "\n",
        "        # Extract the sample ID and create separate columns\n",
        "        data[\"Block\"] = data[sampleid_column].apply(lambda x: block_key.get(x.split('-')[1] if isinstance(x, str) else None))\n",
        "        data[\"Treatment\"] = data[sampleid_column].apply(lambda x: treatment_key.get(x.split('-')[2] if isinstance(x, str) else None))\n",
        "        data[\"Row_type\"] = data[sampleid_column].apply(lambda x: spatial_key.get(x.split('-')[3], None))\n",
        "        data[\"Depth\"] = data[sampleid_column].apply(lambda x: depth_key.get(x.split('-')[4], None))\n",
        "        data[\"Time\"] = data.apply(lambda row: row.get(\"Time\", \"N/A\"), axis=1)\n",
        "\n",
        "        # Create the new_sample_ID column\n",
        "        data[\"new_sample_ID\"] = data.apply(lambda row: f\"{row['Crop']}-{row['site']}-{row['season']}-S{row.name + 1}\", axis=1)\n",
        "\n",
        "        # Sort the columns\n",
        "        column_order = [\n",
        "            sampleid_column,\n",
        "            \"new_sample_ID\",\n",
        "            \"Sampling Date\",\n",
        "            \"Crop\",\n",
        "            \"site\",\n",
        "            \"season\",\n",
        "            \"Treatment\",\n",
        "            \"Block\",\n",
        "            \"Row_type\",\n",
        "            \"Depth\",\n",
        "            \"Time\",\n",
        "            \"sample_type\"\n",
        "        ]\n",
        "\n",
        "        # Create a list of columns that are not in column_order\n",
        "        remaining_columns = [col for col in data.columns if col not in column_order]\n",
        "\n",
        "        # Append the remaining columns to the column_order list\n",
        "        column_order += remaining_columns\n",
        "\n",
        "        # Reorder the columns in the DataFrame based on column_order\n",
        "        data = data[column_order]\n",
        "\n",
        "        # Print the modified data\n",
        "        print(\"\\nModified data:\")\n",
        "        print(data)\n",
        "\n",
        "        # Create the output file path\n",
        "        file_name = os.path.basename(file)\n",
        "        output_file = os.path.join(output_folder, file_name.replace('.xlsx', '_Masterfile_preprocessed.xlsx'))\n",
        "\n",
        "        # Save the modified data to a new Excel file\n",
        "        data.to_excel(output_file, index=False)\n",
        "        print(f\"Processed data saved to '{output_file}'.\")\n",
        "    else:\n",
        "        print(\"Fieldid column not found in the Excel file.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Set the folder paths for input and output files\n",
        "input_folder = r''\n",
        "output_folder = r''\n",
        "# Get a list of all Excel files in the input folder\n",
        "excel_files = glob.glob(input_folder + '/*.xlsx')\n",
        "# Process each Excel file\n",
        "for file in excel_files:\n",
        "    # Read the Excel file\n",
        "    data = pd.read_excel(file)\n",
        "    # Print the column names\n",
        "\n",
        "    column_names = data.columns\n",
        "    # Ask for the columns to delete\n",
        "    columns_to_delete = ['AcctNo','Company','FieldID','First','Last','Address','City','State','Zip','Country','Grower','FarmID','LabID','Received','Processed','Matrix']\n",
        "\n",
        "\n",
        "    # Delete the specified columns\n",
        "    data.drop(columns=columns_to_delete, inplace=True)\n",
        "    #Print the column names\n",
        "    column_names = data.columns\n",
        "    for name in column_names:\n",
        "\n",
        "    # Ask for the sampleid column\n",
        "     sampleid_column = 'SampleID'\n",
        "\n",
        "    # Extract the data based on the fieldid column\n",
        "    if sampleid_column in column_names:\n",
        "        # Get the first three characters of the fieldid column as the farm ID\n",
        "        farm_id = data[sampleid_column].apply(lambda x:x.split('-')[0])\n",
        "\n",
        "        # Create new columns based on the farm ID and perform the required transformations\n",
        "        block_key={\n",
        "                'A':'1',\n",
        "                'B':'2',\n",
        "                'C':'3',\n",
        "                'D':'4'\n",
        "\n",
        "            }\n",
        "        crop_key = {\n",
        "            'T1': 'TO',\n",
        "            'T2': 'TO',\n",
        "            'T3': 'TO',\n",
        "            'P1': 'PT',\n",
        "            'P2': 'PT',\n",
        "            'B1': 'GB',\n",
        "            'B2': 'GB'\n",
        "        }\n",
        "\n",
        "        site_key = {\n",
        "            'T1': 'LL', #\n",
        "            'T2': 'PI', #\n",
        "            'T3': 'LE', #\n",
        "            'P1': 'TI', #\n",
        "            'P2': 'TL', #\n",
        "            'B1': 'CC', #\n",
        "            'B2': 'HW'  #\n",
        "        }\n",
        "        season_key = {\n",
        "            'T1': 'F3', # 09/29-30/2023\n",
        "            'T2': 'W3', # 11/07/2023\n",
        "            'T3': 'W3', #\n",
        "            'P1': 'W3', # 11/02/2023\n",
        "            'P2': 'W3', #\n",
        "            'B1': 'W3', # 11/22/2023\n",
        "            'B2': 'W3' #\n",
        "        }\n",
        "        spatial_key = {\n",
        "                'DR': 'DR',  # Ditch row\n",
        "                'FN': 'FN',  # First neighbor\n",
        "                'SN': 'SN' ,  # Second neighbor\n",
        "                'ND': 'ND'   # Second neighbor\n",
        "            }\n",
        "        farm_ids = set(farm_id.tolist())\n",
        "        if 'T1' in farm_ids or  'T2'in farm_ids or 'T3'in farm_ids:\n",
        "\n",
        "            depth_key = {\n",
        "                'S1': '15', #6 inch\n",
        "                'S2': '30', #12 inch\n",
        "                'S3': '45' #18 inch\n",
        "            }\n",
        "            treatment_key = {\n",
        "                '1': '0',\n",
        "                '2': '50',\n",
        "                '3': '75',\n",
        "                '4': '100',\n",
        "                '5': '150',\n",
        "                '6': '200'\n",
        "\n",
        "            }\n",
        "\n",
        "        elif 'P1' in farm_ids or 'P2' in farm_ids:\n",
        "\n",
        "            depth_key = {\n",
        "                'S1': '20', #8 inch\n",
        "                'S2': '40', #16 inch\n",
        "                'S3': '60'  #24 inch\n",
        "            }\n",
        "            treatment_key = {\n",
        "                '1': '0',\n",
        "                '2': '46',\n",
        "                '3': '92',\n",
        "                '4': '137',\n",
        "                '5': '183',\n",
        "                '6': '229'\n",
        "\n",
        "            }\n",
        "        else:\n",
        "\n",
        "            depth_key = {\n",
        "                'S1': '15', #6 inch\n",
        "                'S2': '30', #12 inch\n",
        "                'S3': '45'  #18 inch\n",
        "            }\n",
        "            treatment_key = {\n",
        "                '1': '0',\n",
        "                '2': '40',\n",
        "                '3': '80',\n",
        "                '4': '120',\n",
        "                '5': '113L'\n",
        "            }\n",
        "        # Create new columns based on the farm ID and perform the required transformations\n",
        "        data[\"Crop\"] = farm_id.apply(lambda x: crop_key.get(x, None))\n",
        "        data[\"site\"] = farm_id.apply(lambda x: site_key.get(x, None))\n",
        "        data[\"season\"] = farm_id.apply(lambda x: season_key.get(x, None))\n",
        "\n",
        "         # Convert \"Sampling Date\" to a datetime object\n",
        "        data[\"Sampling Date\"] = pd.to_datetime(data[sampleid_column].apply(lambda x: x.split('-')[5]), format='%m%d%Y').dt.date\n",
        "\n",
        "        data[\"sample_type\"] = \"S\"\n",
        "        # Extract the sample ID and create separate columns\n",
        "        data[\"Block\"] = data[sampleid_column].apply(lambda x:  block_key.get(x.split('-')[1] if isinstance(x, str) else None))\n",
        "        data[\"Treatment\"] = data[sampleid_column].apply(lambda x: treatment_key.get(x.split('-')[2] if isinstance(x, str) else None))\n",
        "        data[\"Row_type\"] = data[sampleid_column].apply(lambda x: spatial_key.get(x.split('-')[3], None))\n",
        "        data[\"Depth\"] = data[sampleid_column].apply(lambda x: depth_key.get(x.split('-')[4], None))\n",
        "        data[\"Time\"] = data.apply(lambda row: row.get(\"Time\", \"N/A\"), axis=1)\n",
        "        # Create the new_sample_ID column\n",
        "        data[\"new_sample_ID\"] = data.apply(lambda row: f\"{row['Crop']}-{row['site']}-{row['season']}-S{row.name + 1}\", axis=1)\n",
        "\n",
        "        # Sort the columns\n",
        "        column_order = [\n",
        "            sampleid_column,\n",
        "            \"new_sample_ID\",\n",
        "            \"Sampling Date\",\n",
        "            \"Crop\",\n",
        "            \"site\",\n",
        "            \"season\",\n",
        "            \"Treatment\",\n",
        "            \"Block\",\n",
        "            \"Row_type\",\n",
        "            \"Depth\",\n",
        "            \"Time\",\n",
        "            \"sample_type\"\n",
        "        ]\n",
        "        # Create a list of columns that are not in column_order\n",
        "        remaining_columns = [col for col in column_names if col not in column_order]\n",
        "\n",
        "        # Append the remaining columns to the column_order list\n",
        "        column_order += remaining_columns\n",
        "\n",
        "        # Reorder the columns in the DataFrame based on column_order\n",
        "        data = data[column_order]\n",
        "\n",
        "\n",
        "        # Print the modified data\n",
        "        print(\"\\nModified data:\")\n",
        "        print(data)\n",
        "       # Create the output file path\n",
        "        file_name = os.path.basename(file)\n",
        "        output_file = os.path.join(output_folder, file_name.replace('.xlsx', '_Masterfile_preprocessed.xlsx'))\n",
        "        # Save the modified data to a new Excel file in the outp\n",
        "        data.to_excel(output_file, index=False)\n",
        "        print(f\"Processed data saved to '{output_file}'.\")\n",
        "    else:\n",
        "      print(\"Fieldid column not found in the Excel file.\")"
      ],
      "metadata": {
        "id": "JbPMBcK0SPNd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}